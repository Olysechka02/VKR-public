import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import pandas as pd
import os
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score
from sklearn.model_selection import train_test_split
import time
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import gc
from tqdm import tqdm  # –ò–∑–º–µ–Ω–µ–Ω–æ –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ
import warnings
#warnings.filterwarnings('ignore')

# ====================================================
# üîß –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ú–û–î–ï–õ–ò –ò –ü–£–¢–ò –ö –î–ê–ù–ù–´–ú
# ====================================================
class Config:
    # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ
    PARQUET_DIR = r"C:\Users\–ï5\Documents\olesya\vkr\drone\features_win20_hop12_mel64_feat1280\combined"    
    ALL_DATA_PATH = os.path.join(PARQUET_DIR, "all_data.parquet")

    BASE_RESULTS_DIR = r"C:\Users\–ï5\Documents\olesya\vkr"
    RESULTS_DIR = os.path.join(BASE_RESULTS_DIR, "mel-1280-resnet-se-mtl-1-cnn_results")
    
    # ‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    WIN_LEN = 20
    N_MELS = 64
    N_FEATURES = WIN_LEN * N_MELS
    
    # üìä –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    TRAIN_RATIO = 0.6
    VALID_RATIO = 0.2
    TEST_RATIO = 0.2
    
    # üéØ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
    BATCH_SIZE = 128
    LEARNING_RATE = 0.001
    EPOCHS = 50
    EARLY_STOPPING_PATIENCE = 7
    
    # üöÄ –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç
    QUICK_TEST = False
    QUICK_SAMPLE_SIZE = 971721  # –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞

config = Config()

# ====================================================
# üß† –ë–õ–û–ö SQUEEZE-AND-EXCITATION (SE)
# ====================================================
class SELayer(nn.Module):
    """–°–ª–æ–π –≤–Ω–∏–º–∞–Ω–∏—è –∫ –∫–∞–Ω–∞–ª–∞–º –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    def __init__(self, channel, reduction=16):
        super(SELayer, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(channel, channel // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channel // reduction, channel, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1, 1)
        return x * y.expand_as(x)

# ====================================================
# üîÑ RESIDUAL –ë–õ–û–ö –° SE –í–ù–ò–ú–ê–ù–ò–ï–ú
# ====================================================
class SEResidualBlock(nn.Module):
    """–ë–ª–æ–∫ —Å –æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º–∏ —Å–≤—è–∑—è–º–∏ –∏ –º–µ—Ö–∞–Ω–∏–∑–º–æ–º –≤–Ω–∏–º–∞–Ω–∏—è –∫ –∫–∞–Ω–∞–ª–∞–º"""
    def __init__(self, in_channels, out_channels, stride=1, downsample=None, reduction=16):
        super().__init__()
        
        # –ü–µ—Ä–≤–∞—è —Å–≤–µ—Ä—Ç–∫–∞
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, 
                               stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        
        # –í—Ç–æ—Ä–∞—è —Å–≤–µ—Ä—Ç–∫–∞
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,
                               stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        
        # SE –±–ª–æ–∫ –¥–ª—è –≤–Ω–∏–º–∞–Ω–∏—è –∫ –∫–∞–Ω–∞–ª–∞–º
        self.se = SELayer(out_channels, reduction)
        
        # –ü—Ä–æ–ø—É—Å–∫ —Å–≤—è–∑–∏ –¥–ª—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
        self.downsample = downsample
        self.stride = stride
        
    def forward(self, x):
        identity = x
        
        # –û—Å–Ω–æ–≤–Ω–æ–π –ø—É—Ç—å
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        
        out = self.conv2(out)
        out = self.bn2(out)
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ SE –≤–Ω–∏–º–∞–Ω–∏—è
        out = self.se(out)
        
        # –ü—Ä–æ–ø—É—Å–∫ —Å–≤—è–∑–∏ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å)
        if self.downsample is not None:
            identity = self.downsample(x)
        
        # –°–ª–æ–∂–µ–Ω–∏–µ —Å –ø—Ä–æ–ø—É—Å–∫–æ–º
        out += identity
        out = self.relu(out)
        
        return out

# ====================================================
# ü§ñ –ú–ù–û–ì–û–ó–ê–î–ê–ß–ù–ê–Ø –ú–û–î–ï–õ–¨ RESNET –° SE (–û–ë–ù–û–í–õ–ï–ù–ù–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê)
# ====================================================
class OptimalResNetSEMTLCNN_Enhanced(nn.Module):
    """
    –£–ª—É—á—à–µ–Ω–Ω–∞—è –º–Ω–æ–≥–æ–∑–∞–¥–∞—á–Ω–∞—è CNN –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º–∏ —Å–ª–æ—è–º–∏
    –∏ –º–µ—Ö–∞–Ω–∏–∑–º–æ–º –≤–Ω–∏–º–∞–Ω–∏—è –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–µ–∏—Å–ø—Ä–∞–≤–Ω–æ—Å—Ç–µ–π –∏ –º–∞–Ω–µ–≤—Ä–æ–≤
    """
    def __init__(self, n_fault_classes, n_maneuver_classes, win_len=20, n_mels=64):
        super().__init__()
        
        # üîπ –ù–∞—á–∞–ª—å–Ω—ã–π —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π —Å–ª–æ–π (–£–í–ï–õ–ò–ß–ï–ù –¥–æ 32 –∫–∞–Ω–∞–ª–æ–≤)
        self.conv1 = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2)  # –°–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏: 20√ó64 ‚Üí 10√ó32
        )
        
        # üîπ Stage 1: –ü–µ—Ä–≤—ã–π –Ω–∞–±–æ—Ä –æ—Å—Ç–∞—Ç–æ—á–Ω—ã—Ö –±–ª–æ–∫–æ–≤ (–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω –ø–æ–¥ 32 –∫–∞–Ω–∞–ª–∞)
        self.stage1 = self._make_stage(32, 64, 2)  # 32 ‚Üí 64 –∫–∞–Ω–∞–ª–æ–≤
        
        # üîπ Stage 2: –í—Ç–æ—Ä–æ–π –Ω–∞–±–æ—Ä –æ—Å—Ç–∞—Ç–æ—á–Ω—ã—Ö –±–ª–æ–∫–æ–≤ —Å –ø–æ–Ω–∏–∂–µ–Ω–∏–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
        self.stage2 = self._make_stage(64, 128, 2, stride=2)  # 64 ‚Üí 128 –∫–∞–Ω–∞–ª–æ–≤
        
        # üîπ Stage 3: –¢—Ä–µ—Ç–∏–π –Ω–∞–±–æ—Ä –æ—Å—Ç–∞—Ç–æ—á–Ω—ã—Ö –±–ª–æ–∫–æ–≤
        self.stage3 = self._make_stage(128, 192, 1, stride=2)  # 128 ‚Üí 256 –∫–∞–Ω–∞–ª–æ–≤
        
        # üîπ –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))
        
        # üîπ –û–±—â–∏–µ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (DROPOUT –£–í–ï–õ–ò–ß–ï–ù –≤ 2 —Ä–∞–∑–∞: 0.5 ‚Üí 0.25)
        self.shared_fc = nn.Sequential(
            nn.Linear(192, 96),  # –í—Ö–æ–¥ —É–≤–µ–ª–∏—á–µ–Ω —Å 128 –¥–æ 256
            nn.BatchNorm1d(96),
            nn.ReLU(inplace=True),
            nn.Dropout(0.25),  # –£–≤–µ–ª–∏—á–µ–Ω dropout
            
            nn.Linear(96, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(inplace=True),
            nn.Dropout(0.25),  # –£–≤–µ–ª–∏—á–µ–Ω dropout
            
            nn.Linear(64, 64),
        )
        
        # üîπ –ì–æ–ª–æ–≤–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–µ–∏—Å–ø—Ä–∞–≤–Ω–æ—Å—Ç–µ–π (–£–í–ï–õ–ò–ß–ï–ù–ê –≤ 2 —Ä–∞–∑–∞)
        self.fault_head = nn.Sequential(
            nn.Linear(64, 96),  # –£–≤–µ–ª–∏—á–µ–Ω–æ –≤ 2 —Ä–∞–∑–∞ (–±—ã–ª–æ 128)
            nn.ReLU(inplace=True),
            nn.Dropout(0.15),  # –£–≤–µ–ª–∏—á–µ–Ω dropout (0.3 ‚Üí 0.15)
            nn.Linear(96, n_fault_classes)
        )
        
        # üîπ –ì–æ–ª–æ–≤–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –º–∞–Ω–µ–≤—Ä–æ–≤ (–£–í–ï–õ–ò–ß–ï–ù–ê –≤ 2 —Ä–∞–∑–∞)
        self.maneuver_head = nn.Sequential(
            nn.Linear(64, 48),  # –£–≤–µ–ª–∏—á–µ–Ω–æ –≤ 2 —Ä–∞–∑–∞ (–±—ã–ª–æ 64)
            nn.ReLU(inplace=True),
            nn.Dropout(0.15),  # –£–≤–µ–ª–∏—á–µ–Ω dropout (0.3 ‚Üí 0.15)
            nn.Linear(48, n_maneuver_classes)
        )
        
        # üîπ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
        self._initialize_weights()
        
        # üî¢ –ü–æ–¥—Å—á–µ—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        self.total_params = sum(p.numel() for p in self.parameters())
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞. –í—Å–µ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {self.total_params:,}")
    
    def _make_stage(self, in_channels, out_channels, blocks, stride=1):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –æ—Å—Ç–∞—Ç–æ—á–Ω—ã—Ö –±–ª–æ–∫–æ–≤"""
        downsample = None
        if stride != 1 or in_channels != out_channels:
            downsample = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1, 
                         stride=stride, bias=False),
                nn.BatchNorm2d(out_channels),
            )
        
        layers = []
        layers.append(SEResidualBlock(in_channels, out_channels, stride, downsample))
        
        for _ in range(1, blocks):
            layers.append(SEResidualBlock(out_channels, out_channels))
        
        return nn.Sequential(*layers)
    
    def _initialize_weights(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏"""
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.xavier_normal_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
    
    def forward(self, x):
        """–ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å"""
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–∑–º–µ—Ä–µ–Ω–∏—è –¥–ª—è –∫–∞–Ω–∞–ª–∞
        x = x.unsqueeze(1)
        
        # –ü—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–µ —Å–ª–æ–∏ —Å –Ω–æ–≤—ã–º–∏ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—è–º–∏
        x = self.conv1(x)      # 1√ó20√ó64 ‚Üí 32√ó10√ó32
        x = self.stage1(x)     # 32√ó10√ó32 ‚Üí 64√ó10√ó32
        x = self.stage2(x)     # 64√ó10√ó32 ‚Üí 128√ó5√ó16
        x = self.stage3(x)     # 128√ó5√ó16 ‚Üí 256√ó3√ó8
        
        # –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –∏ –≤—ã—Ç—è–≥–∏–≤–∞–Ω–∏–µ –≤ –≤–µ–∫—Ç–æ—Ä
        x = self.global_pool(x)
        x = x.view(x.size(0), -1)
        
        # –û–±—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –æ–±–µ–∏—Ö –∑–∞–¥–∞—á
        shared_features = self.shared_fc(x)
        
        # –ü—Ä–æ–≥–Ω–æ–∑—ã –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏
        fault_output = self.fault_head(shared_features)
        maneuver_output = self.maneuver_head(shared_features)
        
        return fault_output, maneuver_output

# ====================================================
# üìä –°–¢–†–ê–¢–ò–§–ò–¶–ò–†–û–í–ê–ù–ù–û–ï –†–ê–ó–î–ï–õ–ï–ù–ò–ï –î–ê–ù–ù–´–•
# ====================================================
def load_and_split_data(all_data_path, quick_test=False, sample_size=None):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/valid/test"""
    print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö...")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
    all_df = pd.read_parquet(all_data_path)
    
    # –†–µ–∂–∏–º –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    if quick_test and sample_size:
        print(f"üöÄ –†–µ–∂–∏–º –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞")
        print(f"   üìã –ó–∞–ø—Ä–æ—à–µ–Ω–æ –ø—Ä–∏–º–µ—Ä–æ–≤: {sample_size}")
        print(f"   üìä –í—Å–µ–≥–æ –¥–æ—Å—Ç—É–ø–Ω–æ: {len(all_df):,}")
        
        if sample_size >= len(all_df):
            print("   ‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ.")
        else:
            # –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª—é—á–∞ –¥–ª—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
            all_df['stratify_key'] = all_df['model_type'] + '_' + all_df['fault'] + '_' + all_df['maneuvering_direction']
            
            unique_strata = all_df['stratify_key'].unique()
            sampled_dfs = []
            
            # –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –ø–æ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞—Ç–µ
            for stratum in unique_strata:
                stratum_df = all_df[all_df['stratify_key'] == stratum].copy()
                stratum_ratio = len(stratum_df) / len(all_df)
                stratum_sample_size = max(1, int(sample_size * stratum_ratio))
                
                if len(stratum_df) <= stratum_sample_size:
                    sampled_dfs.append(stratum_df)
                else:
                    sampled_stratum = stratum_df.sample(n=stratum_sample_size, random_state=42)
                    sampled_dfs.append(sampled_stratum)
            
            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö —Å—Ç—Ä–∞—Ç
            all_df = pd.concat(sampled_dfs, ignore_index=True)
            print(f"   ‚úÖ –ü–æ–ª—É—á–µ–Ω–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –ø–æ—Å–ª–µ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏: {len(all_df):,}")
            
            # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
            all_df = all_df.sample(frac=1, random_state=42).reset_index(drop=True)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
    required_cols = ['fault', 'model_type', 'maneuvering_direction']
    missing_cols = [col for col in required_cols if col not in all_df.columns]
    if missing_cols:
        raise KeyError(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏: {missing_cols}")
    
    print(f"\nüìà –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(all_df):,}")
    
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    all_df = all_df[
        (all_df['fault'] != 'unknown') & 
        (all_df['maneuvering_direction'] != 'unknown') &
        (all_df['model_type'] != 'unknown')
    ].copy()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª—é—á–∞ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
    all_df['stratify_key'] = all_df['model_type'] + '_' + all_df['fault'] + '_' + all_df['maneuvering_direction']
    
    # –ü–µ—Ä–≤–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ: train –∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä (valid + test)
    train_df, temp_df = train_test_split(
        all_df, 
        test_size=config.VALID_RATIO + config.TEST_RATIO,
        stratify=all_df['stratify_key'],
        random_state=42
    )
    
    # –í—Ç–æ—Ä–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ: valid –∏ test
    valid_test_ratio = config.TEST_RATIO / (config.VALID_RATIO + config.TEST_RATIO)
    valid_df, test_df = train_test_split(
        temp_df,
        test_size=valid_test_ratio,
        stratify=temp_df['stratify_key'],
        random_state=42
    )
    
    print(f"\n‚úÖ –î–∞–Ω–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–µ–Ω—ã:")
    print(f"   üü¢ Train: {len(train_df):,} –∑–∞–ø–∏—Å–µ–π ({len(train_df)/len(all_df)*100:.1f}%)")
    print(f"   üü° Valid: {len(valid_df):,} –∑–∞–ø–∏—Å–µ–π ({len(valid_df)/len(all_df)*100:.1f}%)")
    print(f"   üî¥ Test:  {len(test_df):,} –∑–∞–ø–∏—Å–µ–π ({len(test_df)/len(all_df)*100:.1f}%)")
    
    return train_df, valid_df, test_df

# ====================================================
# üì¶ DATASET –ò DATALOADER –î–õ–Ø –ú–ù–û–ì–û–ó–ê–î–ê–ß–ù–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø
# ====================================================
class MultiTaskDroneDataset(Dataset):
    """–î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –º–Ω–æ–≥–æ–∑–∞–¥–∞—á–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏ –¥–≤—É–º—è –º–µ—Ç–∫–∞–º–∏"""
    def __init__(self, features, fault_labels, maneuver_labels, model_types=None):
        self.features = torch.FloatTensor(features)
        self.fault_labels = torch.LongTensor(fault_labels)
        self.maneuver_labels = torch.LongTensor(maneuver_labels)
        self.model_types = model_types
        
    def __len__(self):
        return len(self.features)
    
    def __getitem__(self, idx):
        if self.model_types is not None:
            return (self.features[idx], 
                    self.fault_labels[idx], 
                    self.maneuver_labels[idx],
                    self.model_types[idx])
        else:
            return (self.features[idx], 
                    self.fault_labels[idx], 
                    self.maneuver_labels[idx])

# ====================================================
# üìä –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò –î–õ–Ø –û–ë–£–ß–ï–ù–ò–Ø
# ====================================================
def calculate_f1_score(true_labels, pred_labels, average='weighted'):
    """–†–∞—Å—á–µ—Ç F1-–º–µ—Ä—ã –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    return f1_score(true_labels, pred_labels, average=average)

def train_mtl_model_f1(model, train_loader, valid_loader, optimizer, fault_criterion, maneuver_criterion, scheduler, device, epochs=30):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è –º–Ω–æ–≥–æ–∑–∞–¥–∞—á–Ω–æ–π –º–æ–¥–µ–ª–∏ —Å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ–º F1"""
    # üìà –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è
    train_losses = []
    valid_losses = []
    train_fault_acc = []
    train_maneuver_acc = []
    valid_fault_acc = []
    valid_maneuver_acc = []
    
    train_fault_f1 = []
    train_maneuver_f1 = []
    valid_fault_f1 = []
    valid_maneuver_f1 = []
    
    iteration_losses = []
    
    # üèÜ –õ—É—á—à–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –¥–ª—è —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
    best_valid_f1 = 0
    best_model_state = None
    patience_counter = 0
    
    start_time = time.time()
    iteration = 0
    
    # üîÑ –¶–∏–∫–ª –ø–æ —ç–ø–æ—Ö–∞–º
    for epoch in range(epochs):
        print(f"\nüìà –≠–ü–û–•–ê {epoch+1}/{epochs}")
        
        # ==================== –§–ê–ó–ê –û–ë–£–ß–ï–ù–ò–Ø ====================
        model.train()
        train_total_loss = 0
        train_fault_correct = 0
        train_maneuver_correct = 0
        train_total = 0
        
        train_fault_preds = []
        train_fault_targets = []
        train_maneuver_preds = []
        train_maneuver_targets = []
        
        train_pbar = tqdm(train_loader, desc="üéì –û–±—É—á–µ–Ω–∏–µ", leave=False)
        for batch_idx, (data, fault_target, maneuver_target, _) in enumerate(train_pbar):
            # –ü–µ—Ä–µ–Ω–æ—Å –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
            data = data.to(device)
            fault_target = fault_target.to(device)
            maneuver_target = maneuver_target.to(device)
            
            # –û–±–Ω—É–ª–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
            optimizer.zero_grad()
            
            # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥
            fault_output, maneuver_output = model(data)
            
            # –†–∞—Å—á–µ—Ç –ø–æ—Ç–µ—Ä—å
            fault_loss = fault_criterion(fault_output, fault_target)
            maneuver_loss = maneuver_criterion(maneuver_output, maneuver_target)
            total_loss = 0.8 * fault_loss + 0.2 * maneuver_loss  # –í–∑–≤–µ—à–∏–≤–∞–Ω–∏–µ –∑–∞–¥–∞—á
            
            # –û–±—Ä–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ
            total_loss.backward()
            optimizer.step()
            
            # –ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            train_total_loss += total_loss.item()
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            _, fault_pred = fault_output.max(1)
            _, maneuver_pred = maneuver_output.max(1)
            
            # –ü–æ–¥—Å—á–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            train_fault_correct += fault_pred.eq(fault_target).sum().item()
            train_maneuver_correct += maneuver_pred.eq(maneuver_target).sum().item()
            train_total += fault_target.size(0)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è –º–µ—Ç—Ä–∏–∫
            train_fault_preds.extend(fault_pred.cpu().numpy())
            train_fault_targets.extend(fault_target.cpu().numpy())
            train_maneuver_preds.extend(maneuver_pred.cpu().numpy())
            train_maneuver_targets.extend(maneuver_target.cpu().numpy())
            
            # –ó–∞–ø–∏—Å—å –ø–æ—Ç–µ—Ä—å –Ω–∞ –∏—Ç–µ—Ä–∞—Ü–∏–∏
            iteration += 1
            iteration_losses.append({
                'iteration': iteration,
                'fault_loss': fault_loss.item(),
                'maneuver_loss': maneuver_loss.item(),
                'total_loss': total_loss.item()
            })
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
            train_pbar.set_postfix({
                'loss': f'{total_loss.item():.4f}',
                'fault_acc': f'{100.*train_fault_correct/train_total:.1f}%',
                'maneuver_acc': f'{100.*train_maneuver_correct/train_total:.1f}%'
            })
        
        # üìä –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –¥–ª—è –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏
        train_fault_f1_score = calculate_f1_score(train_fault_targets, train_fault_preds)
        train_maneuver_f1_score = calculate_f1_score(train_maneuver_targets, train_maneuver_preds)
        
        avg_train_loss = train_total_loss / len(train_loader)
        train_fault_accuracy = 100. * train_fault_correct / train_total
        train_maneuver_accuracy = 100. * train_maneuver_correct / train_total
        
        # ==================== –§–ê–ó–ê –í–ê–õ–ò–î–ê–¶–ò–ò ====================
        model.eval()
        valid_total_loss = 0
        valid_fault_correct = 0
        valid_maneuver_correct = 0
        valid_total = 0
        
        valid_fault_preds = []
        valid_fault_targets = []
        valid_maneuver_preds = []
        valid_maneuver_targets = []
        
        valid_pbar = tqdm(valid_loader, desc="üß™ –í–∞–ª–∏–¥–∞—Ü–∏—è", leave=False)
        with torch.no_grad():
            for data, fault_target, maneuver_target, _ in valid_pbar:
                data = data.to(device)
                fault_target = fault_target.to(device)
                maneuver_target = maneuver_target.to(device)
                
                # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ –±–µ–∑ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
                fault_output, maneuver_output = model(data)
                
                # –†–∞—Å—á–µ—Ç –ø–æ—Ç–µ—Ä—å
                fault_loss = fault_criterion(fault_output, fault_target)
                maneuver_loss = maneuver_criterion(maneuver_output, maneuver_target)
                total_loss = 0.5 * fault_loss + 0.5 * maneuver_loss  # –†–∞–≤–Ω–æ–µ –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏–µ
                
                # –ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                valid_total_loss += total_loss.item()
                
                # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
                _, fault_pred = fault_output.max(1)
                _, maneuver_pred = maneuver_output.max(1)
                
                # –ü–æ–¥—Å—á–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
                valid_fault_correct += fault_pred.eq(fault_target).sum().item()
                valid_maneuver_correct += maneuver_pred.eq(maneuver_target).sum().item()
                valid_total += fault_target.size(0)
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è –º–µ—Ç—Ä–∏–∫
                valid_fault_preds.extend(fault_pred.cpu().numpy())
                valid_fault_targets.extend(fault_target.cpu().numpy())
                valid_maneuver_preds.extend(maneuver_pred.cpu().numpy())
                valid_maneuver_targets.extend(maneuver_target.cpu().numpy())
        
        # üìä –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏
        valid_fault_f1_score = calculate_f1_score(valid_fault_targets, valid_fault_preds)
        valid_maneuver_f1_score = calculate_f1_score(valid_maneuver_targets, valid_maneuver_preds)
        
        avg_valid_loss = valid_total_loss / len(valid_loader)
        valid_fault_accuracy = 100. * valid_fault_correct / valid_total
        valid_maneuver_accuracy = 100. * valid_maneuver_correct / valid_total
        
        # üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        train_losses.append(avg_train_loss)
        valid_losses.append(avg_valid_loss)
        train_fault_acc.append(train_fault_accuracy)
        train_maneuver_acc.append(train_maneuver_accuracy)
        valid_fault_acc.append(valid_fault_accuracy)
        valid_maneuver_acc.append(valid_maneuver_accuracy)
        
        train_fault_f1.append(train_fault_f1_score)
        train_maneuver_f1.append(train_maneuver_f1_score)
        valid_fault_f1.append(valid_fault_f1_score)
        valid_maneuver_f1.append(valid_maneuver_f1_score)
        
        # üéØ –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è F1-–º–µ—Ä–∞ –¥–ª—è —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
        valid_combined_f1 = 0.8 * valid_fault_f1_score + 0.2 * valid_maneuver_f1_score
        
        # üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è
        scheduler.step(valid_combined_f1)
        current_lr = optimizer.param_groups[0]['lr']
        
        # üìã –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —ç–ø–æ—Ö–∏
        print(f"üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –≠–ü–û–•–ò {epoch+1}:")
        print(f"   üéì Train Loss: {avg_train_loss:.4f} | üîß Fault Acc: {train_fault_accuracy:.2f}% | üöÅ Maneuver Acc: {train_maneuver_accuracy:.2f}%")
        print(f"   üß™ Valid Loss: {avg_valid_loss:.4f} | üîß Fault Acc: {valid_fault_accuracy:.2f}% | üöÅ Maneuver Acc: {valid_maneuver_accuracy:.2f}%")
        print(f"   üéì Train F1 - üîß: {train_fault_f1_score:.4f} | üöÅ: {train_maneuver_f1_score:.4f}")
        print(f"   üß™ Valid F1 - üîß: {valid_fault_f1_score:.4f} | üöÅ: {valid_maneuver_f1_score:.4f}")
        print(f"   üéØ Valid Combined F1: {valid_combined_f1:.4f}")
        print(f"   üìâ LR: {current_lr:.6f}")
        
        # üèÜ –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
        if valid_combined_f1 > best_valid_f1:
            best_valid_f1 = valid_combined_f1
            best_model_state = model.state_dict().copy()
            patience_counter = 0
            print(f"   üéâ –ù–û–í–´–ô –†–ï–ö–û–†–î F1! –õ—É—á—à–∏–π F1: {valid_combined_f1:.4f}")
        else:
            patience_counter += 1
            print(f"   ‚è≥ Early stopping: {patience_counter}/{config.EARLY_STOPPING_PATIENCE}")
            
            # üî¥ –†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞
            if patience_counter >= config.EARLY_STOPPING_PATIENCE:
                print(f"   üõë –†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–∞ —ç–ø–æ—Ö–µ {epoch+1}")
                break
        
        # üßπ –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
        torch.cuda.empty_cache() if torch.cuda.is_available() else gc.collect()
    
    # ‚è±Ô∏è –†–∞—Å—á–µ—Ç –æ–±—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –æ–±—É—á–µ–Ω–∏—è
    total_time = time.time() - start_time
    
    # üì¶ –í–æ–∑–≤—Ä–∞—Ç –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    return {
        'train_losses': train_losses,
        'valid_losses': valid_losses,
        'train_fault_acc': train_fault_acc,
        'train_maneuver_acc': train_maneuver_acc,
        'valid_fault_acc': valid_fault_acc,
        'valid_maneuver_acc': valid_maneuver_acc,
        'train_fault_f1': train_fault_f1,
        'train_maneuver_f1': train_maneuver_f1,
        'valid_fault_f1': valid_fault_f1,
        'valid_maneuver_f1': valid_maneuver_f1,
        'iteration_losses': iteration_losses,
        'best_valid_f1': best_valid_f1,
        'best_model_state': best_model_state,
        'total_time': total_time
    }

def evaluate_model_with_f1(model, test_loader, fault_encoder, maneuver_encoder, device):
    """–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞—Å—á–µ—Ç–æ–º –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫"""
    model.eval()
    
    # üì¶ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    all_results = {
        'fault_pred': [], 'fault_true': [],
        'maneuver_pred': [], 'maneuver_true': [],
        'model_types': []
    }
    
    # üîç –ü—Ä–æ—Ö–æ–¥ –ø–æ —Ç–µ—Å—Ç–æ–≤—ã–º –¥–∞–Ω–Ω—ã–º
    with torch.no_grad():
        for data, fault_target, maneuver_target, model_types in test_loader:
            data = data.to(device)
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            fault_output, maneuver_output = model(data)
            _, fault_pred = fault_output.max(1)
            _, maneuver_pred = maneuver_output.max(1)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            all_results['fault_pred'].extend(fault_pred.cpu().numpy())
            all_results['maneuver_pred'].extend(maneuver_pred.cpu().numpy())
            all_results['fault_true'].extend(fault_target.numpy())
            all_results['maneuver_true'].extend(maneuver_target.numpy())
            all_results['model_types'].extend(model_types)
    
    # üìä –†–∞—Å—á–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
    fault_acc = accuracy_score(all_results['fault_true'], all_results['fault_pred'])
    maneuver_acc = accuracy_score(all_results['maneuver_true'], all_results['maneuver_pred'])
    
    fault_f1 = f1_score(all_results['fault_true'], all_results['fault_pred'], average='weighted')
    maneuver_f1 = f1_score(all_results['maneuver_true'], all_results['maneuver_pred'], average='weighted')
    combined_f1 = 0.8 * fault_f1 + 0.2 * maneuver_f1
    
    # üìã –î–µ—Ç–∞–ª—å–Ω—ã–µ –æ—Ç—á–µ—Ç—ã –ø–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    fault_report = classification_report(all_results['fault_true'], all_results['fault_pred'], 
                                        target_names=fault_encoder.classes_, output_dict=True)
    maneuver_report = classification_report(all_results['maneuver_true'], all_results['maneuver_pred'],
                                          target_names=maneuver_encoder.classes_, output_dict=True)
    
    # üìä –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø–∞–º –¥—Ä–æ–Ω–æ–≤
    df_results = pd.DataFrame(all_results)
    metrics_by_type = {}
    
    for drone_type in df_results['model_types'].unique():
        type_data = df_results[df_results['model_types'] == drone_type]
        if len(type_data) > 0:
            type_fault_acc = accuracy_score(type_data['fault_true'], type_data['fault_pred'])
            type_maneuver_acc = accuracy_score(type_data['maneuver_true'], type_data['maneuver_pred'])
            
            type_fault_f1 = f1_score(type_data['fault_true'], type_data['fault_pred'], average='weighted')
            type_maneuver_f1 = f1_score(type_data['maneuver_true'], type_data['maneuver_pred'], average='weighted')
            
            metrics_by_type[drone_type] = {
                'fault_accuracy': type_fault_acc,
                'maneuver_accuracy': type_maneuver_acc,
                'fault_f1': type_fault_f1,
                'maneuver_f1': type_maneuver_f1,
                'combined_accuracy': (type_fault_acc + type_maneuver_acc) / 2,
                'combined_f1': 0.8 * type_fault_f1 + 0.2 * type_maneuver_f1,
                'samples': len(type_data)
            }
    
    # üì¶ –í–æ–∑–≤—Ä–∞—Ç –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    return {
        'all': {
            'fault_accuracy': fault_acc,
            'maneuver_accuracy': maneuver_acc,
            'fault_f1': fault_f1,
            'maneuver_f1': maneuver_f1,
            'combined_accuracy': (fault_acc + maneuver_acc) / 2,
            'combined_f1': combined_f1,
            'samples': len(df_results)
        },
        'by_type': metrics_by_type,
        'all_results': all_results,
        'fault_report': fault_report,
        'maneuver_report': maneuver_report
    }

# ====================================================
# üöÄ –ó–ê–©–ò–©–ï–ù–ù–ê–Ø –¢–û–ß–ö–ê –í–•–û–î–ê –î–õ–Ø –ú–ù–û–ì–û–ü–û–¢–û–ß–ù–û–°–¢–ò
# ====================================================
if __name__ == '__main__':
    print("=" * 80)
    print("üéØ –ó–ê–ì–†–£–ó–ö–ê –ò –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ö–ê –î–ê–ù–ù–´–•")
    print("=" * 80)

    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    train_df, valid_df, test_df = load_and_split_data(
        config.ALL_DATA_PATH,
        quick_test=config.QUICK_TEST,
        sample_size=config.QUICK_SAMPLE_SIZE
    )

    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    feature_cols = [col for col in train_df.columns if col.startswith('feature_')]
    if len(feature_cols) != config.N_FEATURES:
        feature_cols = feature_cols[:config.N_FEATURES]

    print(f"\nüîç –ü—Ä–∏–∑–Ω–∞–∫–∏: {len(feature_cols)} –∫–æ–ª–æ–Ω–æ–∫")

    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ numpy –º–∞—Å—Å–∏–≤—ã
    X_train = train_df[feature_cols].values.astype(np.float32)
    X_valid = valid_df[feature_cols].values.astype(np.float32)
    X_test = test_df[feature_cols].values.astype(np.float32)

    # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–∫ –Ω–µ–∏—Å–ø—Ä–∞–≤–Ω–æ—Å—Ç–µ–π
    all_faults = pd.concat([train_df['fault'], valid_df['fault'], test_df['fault']]).unique()
    fault_encoder = LabelEncoder()
    fault_encoder.fit(all_faults)

    y_train_fault = fault_encoder.transform(train_df['fault'])
    y_valid_fault = fault_encoder.transform(valid_df['fault'])
    y_test_fault = fault_encoder.transform(test_df['fault'])

    fault_classes = fault_encoder.classes_
    n_fault_classes = len(fault_classes)

    # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–∫ –º–∞–Ω–µ–≤—Ä–æ–≤
    all_maneuvers = pd.concat([train_df['maneuvering_direction'], valid_df['maneuvering_direction'], test_df['maneuvering_direction']]).unique()
    maneuver_encoder = LabelEncoder()
    maneuver_encoder.fit(all_maneuvers)

    y_train_maneuver = maneuver_encoder.transform(train_df['maneuvering_direction'])
    y_valid_maneuver = maneuver_encoder.transform(valid_df['maneuvering_direction'])
    y_test_maneuver = maneuver_encoder.transform(test_df['maneuvering_direction'])

    maneuver_classes = maneuver_encoder.classes_
    n_maneuver_classes = len(maneuver_classes)

    print(f"\nüéØ –ö–æ–¥–∏—Ä–æ–≤–∫–∞ –º–µ—Ç–æ–∫:")
    print(f"   üîß –ù–µ–∏—Å–ø—Ä–∞–≤–Ω–æ—Å—Ç–∏: {n_fault_classes} –∫–ª–∞—Å—Å–æ–≤")
    print(f"   üöÅ –ú–∞–Ω–µ–≤—Ä—ã: {n_maneuver_classes} –∫–ª–∞—Å—Å–æ–≤")

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –º–æ–¥–µ–ª–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    train_model_types = train_df['model_type'].values
    valid_model_types = valid_df['model_type'].values
    test_model_types = test_df['model_type'].values

    # ====================================================
    # üìè –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–Ø –ü–†–ò–ó–ù–ê–ö–û–í
    # ====================================================
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train).astype(np.float32)
    X_valid_scaled = scaler.transform(X_valid).astype(np.float32)
    X_test_scaled = scaler.transform(X_test).astype(np.float32)

    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ 3D —Ñ–æ—Ä–º–∞—Ç –¥–ª—è CNN (batch_size, win_len, n_mels)
    X_train_3d = X_train_scaled.reshape(-1, config.WIN_LEN, config.N_MELS)
    X_valid_3d = X_valid_scaled.reshape(-1, config.WIN_LEN, config.N_MELS)
    X_test_3d = X_test_scaled.reshape(-1, config.WIN_LEN, config.N_MELS)

    # ====================================================
    # üì¶ –°–û–ó–î–ê–ù–ò–ï –î–ê–¢–ê–°–ï–¢–û–í –ò –î–ê–¢–ê–õ–û–ê–î–ï–†–û–í
    # ====================================================
    train_dataset = MultiTaskDroneDataset(X_train_3d, y_train_fault, y_train_maneuver, train_model_types)
    valid_dataset = MultiTaskDroneDataset(X_valid_3d, y_valid_fault, y_valid_maneuver, valid_model_types)
    test_dataset = MultiTaskDroneDataset(X_test_3d, y_test_fault, y_test_maneuver, test_model_types)

    # üöÄ –°–¢–ê–í–ò–ú 8 –í–û–ö–ï–†–û–í - –¢–ï–ü–ï–†–¨ –≠–¢–û –ë–ï–ó–û–ü–ê–°–ù–û
    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=8)
    valid_loader = DataLoader(valid_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=8)
    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=8)

    print(f"\n‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã:")
    print(f"   üü¢ Train batches: {len(train_loader)}")
    print(f"   üü° Valid batches: {len(valid_loader)}")
    print(f"   üî¥ Test batches:  {len(test_loader)}")

    # ====================================================
    # üèãÔ∏è‚Äç‚ôÇÔ∏è –ü–û–î–ì–û–¢–û–í–ö–ê –ú–û–î–ï–õ–ò –ò –û–ü–¢–ò–ú–ò–ó–ê–¢–û–†–ê
    # ====================================================
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = OptimalResNetSEMTLCNN_Enhanced(n_fault_classes, n_maneuver_classes, config.WIN_LEN, config.N_MELS).to(device)

    print(f"\n‚öôÔ∏è –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    print(f"ü§ñ –ú–æ–¥–µ–ª—å: OptimalResNetSEMTLCNN_Enhanced")

    optimizer = optim.AdamW(model.parameters(), lr=config.LEARNING_RATE, weight_decay=1e-4)
    fault_criterion = nn.CrossEntropyLoss()
    maneuver_criterion = nn.CrossEntropyLoss()

    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='max', factor=0.5, patience=3
    )

    # ====================================================
    # üéØ –ó–ê–ü–£–°–ö –û–ë–£–ß–ï–ù–ò–Ø –ú–û–î–ï–õ–ò
    # ====================================================
    print(f"\nüéØ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏")

    results = train_mtl_model_f1(
        model, train_loader, valid_loader, optimizer, fault_criterion, maneuver_criterion, scheduler, device, epochs=config.EPOCHS
    )

    print(f"\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
    print(f"   ‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è: {results['total_time']/60:.1f} –º–∏–Ω")
    print(f"   üèÜ –õ—É—á—à–∏–π –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π F1: {results['best_valid_f1']:.4f}")
    print(f"   üìà –≠–ø–æ—Ö –≤—ã–ø–æ–ª–Ω–µ–Ω–æ: {len(results['train_losses'])}")

    # –ó–∞–≥—Ä—É–∑–∫–∞ –ª—É—á—à–∏—Ö –≤–µ—Å–æ–≤
    if results['best_model_state'] is not None:
        model.load_state_dict(results['best_model_state'])

    # ====================================================
    # üìä –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –ò –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï
    # ====================================================
    os.makedirs(config.RESULTS_DIR, exist_ok=True)

    # [–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ –æ–±—É—á–µ–Ω–∏—è]
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    epochs_range = range(1, len(results['train_losses']) + 1)

    axes[0, 0].plot(epochs_range, results['train_losses'], 'b-', label='Train Loss', linewidth=2)
    axes[0, 0].plot(epochs_range, results['valid_losses'], 'r-', label='Valid Loss', linewidth=2)
    axes[0, 0].set_title('üìâ –ü–æ—Ç–µ—Ä–∏ –ø–æ —ç–ø–æ—Ö–∞–º')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)

    axes[0, 1].plot(epochs_range, results['train_fault_acc'], 'b-', label='Train', linewidth=2)
    axes[0, 1].plot(epochs_range, results['valid_fault_acc'], 'r-', label='Valid', linewidth=2)
    axes[0, 1].set_title('üéØ –¢–æ—á–Ω–æ—Å—Ç—å –Ω–µ–∏—Å–ø—Ä–∞–≤–Ω–æ—Å—Ç–∏')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)

    axes[0, 2].plot(epochs_range, results['train_maneuver_acc'], 'b-', label='Train', linewidth=2)
    axes[0, 2].plot(epochs_range, results['valid_maneuver_acc'], 'r-', label='Valid', linewidth=2)
    axes[0, 2].set_title('üöÅ –¢–æ—á–Ω–æ—Å—Ç—å –º–∞–Ω–µ–≤—Ä–∞')
    axes[0, 2].legend()
    axes[0, 2].grid(True, alpha=0.3)

    axes[1, 0].plot(epochs_range, results['train_fault_f1'], 'b-', label='Train', linewidth=2)
    axes[1, 0].plot(epochs_range, results['valid_fault_f1'], 'r-', label='Valid', linewidth=2)
    axes[1, 0].set_title('üìä F1-score –Ω–µ–∏—Å–ø—Ä–∞–≤–Ω–æ—Å—Ç–∏')
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)

    axes[1, 1].plot(epochs_range, results['train_maneuver_f1'], 'b-', label='Train', linewidth=2)
    axes[1, 1].plot(epochs_range, results['valid_maneuver_f1'], 'r-', label='Valid', linewidth=2)
    axes[1, 1].set_title('üìà F1-score –º–∞–Ω–µ–≤—Ä–∞')
    axes[1, 1].legend()
    axes[1, 1].grid(True, alpha=0.3)

    if results['iteration_losses']:
        iterations = [x['iteration'] for x in results['iteration_losses']]
        total_losses = [x['total_loss'] for x in results['iteration_losses']]
        window_size = 50
        if len(total_losses) > window_size:
            total_losses_smooth = np.convolve(total_losses, np.ones(window_size)/window_size, mode='valid')
            iterations_smooth = iterations[window_size-1:]
            axes[1, 2].plot(iterations_smooth, total_losses_smooth, 'g-', label='Total Loss (smooth)', linewidth=1)
        else:
            axes[1, 2].plot(iterations, total_losses, 'g-', label='Total Loss', linewidth=1)
        axes[1, 2].set_title('üìä –ü–æ—Ç–µ—Ä–∏ –ø–æ –∏—Ç–µ—Ä–∞—Ü–∏—è–º')
        axes[1, 2].legend()
        axes[1, 2].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(os.path.join(config.RESULTS_DIR, 'training_analysis_enhanced.png'), dpi=120, bbox_inches='tight')

    # [–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ]
    print(f"\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ")
    test_results = evaluate_model_with_f1(model, test_loader, fault_encoder, maneuver_encoder, device)

    print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:")
    print(f"   üîß –ù–µ–∏—Å–ø—Ä–∞–≤–Ω–æ—Å—Ç–∏ - Acc: {test_results['all']['fault_accuracy']*100:.2f}%, F1: {test_results['all']['fault_f1']:.4f}")
    print(f"   üöÅ –ú–∞–Ω–µ–≤—Ä—ã - Acc: {test_results['all']['maneuver_accuracy']*100:.2f}%, F1: {test_results['all']['maneuver_f1']:.4f}")

    # [–ú–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫]
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))

    cm_fault = confusion_matrix(test_results['all_results']['fault_true'], test_results['all_results']['fault_pred'])
    sns.heatmap(cm_fault, annot=True, fmt='d', cmap='Blues', xticklabels=fault_classes, yticklabels=fault_classes, ax=axes[0])
    axes[0].set_title('üîß –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ - –ù–µ–∏—Å–ø—Ä–∞–≤–Ω–æ—Å—Ç–∏')

    cm_maneuver = confusion_matrix(test_results['all_results']['maneuver_true'], test_results['all_results']['maneuver_pred'])
    sns.heatmap(cm_maneuver, annot=True, fmt='d', cmap='Greens', xticklabels=maneuver_classes, yticklabels=maneuver_classes, ax=axes[1])
    axes[1].set_title('üöÅ –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ - –ú–∞–Ω–µ–≤—Ä—ã')

    if test_results['by_type']:
        drone_types = list(test_results['by_type'].keys())
        fault_accs = [test_results['by_type'][t]['fault_accuracy']*100 for t in drone_types]
        maneuver_accs = [test_results['by_type'][t]['maneuver_accuracy']*100 for t in drone_types]
        
        x = np.arange(len(drone_types))
        width = 0.35
        axes[2].bar(x - width/2, fault_accs, width, label='–ù–µ–∏—Å–ø—Ä–∞–≤–Ω–æ—Å—Ç–∏', color='blue', alpha=0.7)
        axes[2].bar(x + width/2, maneuver_accs, width, label='–ú–∞–Ω–µ–≤—Ä—ã', color='green', alpha=0.7)
        axes[2].set_title('üìä –¢–æ—á–Ω–æ—Å—Ç—å –ø–æ —Ç–∏–ø–∞–º –¥—Ä–æ–Ω–∞')
        axes[2].set_xticks(x)
        axes[2].set_xticklabels(drone_types, rotation=45)
        axes[2].legend()

    plt.tight_layout()
    plt.savefig(os.path.join(config.RESULTS_DIR, 'test_results_enhanced.png'), dpi=120, bbox_inches='tight')

    # ====================================================
    # üíæ –°–û–•–†–ê–ù–ï–ù–ò–ï
    # ====================================================
    model_save_path = os.path.join(config.RESULTS_DIR, 'optimal-resnet-se-mtl-cnn_enhanced.pth')
    torch.save({
        'epoch': config.EPOCHS,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'fault_encoder': fault_encoder,
        'maneuver_encoder': maneuver_encoder,
        'scaler': scaler,
        'win_len': config.WIN_LEN,
        'n_mels': config.N_MELS,
        'feature_cols': feature_cols,
        'training_results': results,
        'test_results': test_results,
        'model_params': model.total_params
    }, model_save_path)

    weights_path = os.path.join(config.RESULTS_DIR, 'optimal-resnet-se-mtl-cnn_enhanced_weights.pth')
    torch.save(model.state_dict(), weights_path)

    joblib.dump(scaler, os.path.join(config.RESULTS_DIR, 'scaler_enhanced.pkl'))
    joblib.dump(fault_encoder, os.path.join(config.RESULTS_DIR, 'fault_encoder_enhanced.pkl'))
    joblib.dump(maneuver_encoder, os.path.join(config.RESULTS_DIR, 'maneuver_encoder_enhanced.pkl'))

    all_metrics = {
        'training_results': results,
        'test_results': test_results,
        'fault_classes': fault_classes.tolist(),
        'maneuver_classes': maneuver_classes.tolist(),
        'model_params': model.total_params
    }
    joblib.dump(all_metrics, os.path.join(config.RESULTS_DIR, 'metrics_enhanced.pkl'))

    print(f"\nüíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_save_path}")
    print(f"üî¢ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏: {model.total_params:,}")
    print(f"\nüéâ –í—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω—ã!")